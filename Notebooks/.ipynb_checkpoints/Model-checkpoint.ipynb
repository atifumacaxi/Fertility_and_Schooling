{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0ab87a-5e1a-4951-8cd5-a003c8800e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c523ac13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>fertility</th>\n",
       "      <th>Code</th>\n",
       "      <th>avg_years_of_schooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2007</td>\n",
       "      <td>6.56</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1995</td>\n",
       "      <td>7.61</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2008</td>\n",
       "      <td>6.37</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2017</td>\n",
       "      <td>4.63</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1994</td>\n",
       "      <td>7.57</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Country  Year  fertility Code  avg_years_of_schooling\n",
       "0           0  Afghanistan  2007       6.56  AFG                     2.9\n",
       "1           1  Afghanistan  1995       7.61  AFG                     1.9\n",
       "2           2  Afghanistan  2008       6.37  AFG                     3.0\n",
       "3           3  Afghanistan  2017       4.63  AFG                     3.8\n",
       "4           4  Afghanistan  1994       7.57  AFG                     1.8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../raw_data/treated.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb22b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>fertility</th>\n",
       "      <th>Code</th>\n",
       "      <th>avg_years_of_schooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2007</td>\n",
       "      <td>6.56</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1995</td>\n",
       "      <td>7.61</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2008</td>\n",
       "      <td>6.37</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2017</td>\n",
       "      <td>4.63</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1994</td>\n",
       "      <td>7.57</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>5121</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.03</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>5122</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2000</td>\n",
       "      <td>3.75</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123</th>\n",
       "      <td>5123</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2017</td>\n",
       "      <td>3.71</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5124</th>\n",
       "      <td>5124</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2002</td>\n",
       "      <td>3.72</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5125</th>\n",
       "      <td>5125</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2001</td>\n",
       "      <td>3.73</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5126 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      Country  Year  fertility Code  avg_years_of_schooling\n",
       "0              0  Afghanistan  2007       6.56  AFG                     2.9\n",
       "1              1  Afghanistan  1995       7.61  AFG                     1.9\n",
       "2              2  Afghanistan  2008       6.37  AFG                     3.0\n",
       "3              3  Afghanistan  2017       4.63  AFG                     3.8\n",
       "4              4  Afghanistan  1994       7.57  AFG                     1.8\n",
       "...          ...          ...   ...        ...  ...                     ...\n",
       "5121        5121     Zimbabwe  2010       4.03  ZWE                     7.3\n",
       "5122        5122     Zimbabwe  2000       3.75  ZWE                     6.5\n",
       "5123        5123     Zimbabwe  2017       3.71  ZWE                     8.2\n",
       "5124        5124     Zimbabwe  2002       3.72  ZWE                     6.9\n",
       "5125        5125     Zimbabwe  2001       3.73  ZWE                     6.7\n",
       "\n",
       "[5126 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f97907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Fines adjustments on dataset\n",
    "    '''\n",
    "    #Removing columns\n",
    "    data.drop(columns=['Unnamed: 0', 'Code'], inplace=True)\n",
    "\n",
    "    #Ordering by year and set it as index\n",
    "    data.sort_values('Year', inplace=True)\n",
    "    data.set_index('Year', inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d29977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>fertility</th>\n",
       "      <th>avg_years_of_schooling</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2.37</td>\n",
       "      <td>7.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>6.15</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>4.56</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>6.35</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country  fertility  avg_years_of_schooling\n",
       "Year                                               \n",
       "1960     Germany       2.37                    7.53\n",
       "1960    Thailand       6.15                    2.07\n",
       "1960  Kazakhstan       4.56                    3.07\n",
       "1960     Vietnam       6.35                    2.01\n",
       "1960       Kenya       7.95                    1.21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preproc(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45150e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_X_y(data:pd.DataFrame) -> list:\n",
    "    '''\n",
    "    Given a countries dataset, this function returns\n",
    "    two lists of dataframes, ie., lists containing one dataframe per country.\n",
    "    '''\n",
    "    countries = data.Country.unique().tolist()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    for country in countries:\n",
    "        new_df = data[data['Country']==country][['fertility', 'avg_years_of_schooling']]\n",
    "        \n",
    "        if new_df.shape[0] == 34: #Considering only countries that has 34 samples (34 is the max number of samples)\n",
    "            X.append(new_df.head(33))\n",
    "            y.append(new_df['avg_years_of_schooling'].tail(1))\n",
    "        else:\n",
    "            pass\n",
    "         \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d26c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = list_X_y(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "526043d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming X to a numpy array\n",
    "X_new = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f99af4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming y to a numpy array and adding one dimension ()\n",
    "y_new = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d163db5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 1, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_new = np.expand_dims(y_new.astype(np.float32), axis=-1)\n",
    "y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76b3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99cc74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=20, activation='tanh'))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f4ac099",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', \n",
    "              optimizer='adam', #change to adam\n",
    "                metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4db4778f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 11:40:28.072170: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 105ms/step - loss: 94.8690 - mae: 9.1971 - val_loss: 80.4863 - val_mae: 8.5027\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 91.9903 - mae: 9.0371 - val_loss: 77.7404 - val_mae: 8.3410\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 89.1278 - mae: 8.8782 - val_loss: 74.9914 - val_mae: 8.1799\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 86.3866 - mae: 8.7279 - val_loss: 73.0406 - val_mae: 8.0579\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 84.4814 - mae: 8.6178 - val_loss: 71.6293 - val_mae: 7.9662\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 82.9612 - mae: 8.5248 - val_loss: 70.2448 - val_mae: 7.8752\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 81.5118 - mae: 8.4378 - val_loss: 68.8875 - val_mae: 7.7863\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 80.0298 - mae: 8.3479 - val_loss: 67.4269 - val_mae: 7.6915\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 78.4712 - mae: 8.2532 - val_loss: 65.7702 - val_mae: 7.5868\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 76.6852 - mae: 8.1485 - val_loss: 64.0850 - val_mae: 7.4792\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 74.8381 - mae: 8.0409 - val_loss: 62.4239 - val_mae: 7.3712\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 73.0213 - mae: 7.9317 - val_loss: 60.7409 - val_mae: 7.2598\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 71.1944 - mae: 7.8202 - val_loss: 59.0473 - val_mae: 7.1455\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 69.3672 - mae: 7.7042 - val_loss: 57.3165 - val_mae: 7.0269\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 67.4615 - mae: 7.5851 - val_loss: 55.5196 - val_mae: 6.9014\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 65.5435 - mae: 7.4593 - val_loss: 53.6235 - val_mae: 6.7673\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 63.4728 - mae: 7.3250 - val_loss: 51.6281 - val_mae: 6.6245\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 61.3808 - mae: 7.1840 - val_loss: 49.5259 - val_mae: 6.4709\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 59.0387 - mae: 7.0256 - val_loss: 47.2486 - val_mae: 6.3020\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 56.4687 - mae: 6.8528 - val_loss: 44.8550 - val_mae: 6.1210\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 53.7228 - mae: 6.6649 - val_loss: 42.4335 - val_mae: 5.9323\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 51.1374 - mae: 6.4735 - val_loss: 40.0072 - val_mae: 5.7366\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 48.3733 - mae: 6.2713 - val_loss: 37.6564 - val_mae: 5.5387\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 45.6954 - mae: 6.0702 - val_loss: 35.3926 - val_mae: 5.3384\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 43.1784 - mae: 5.8671 - val_loss: 33.2179 - val_mae: 5.1369\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 40.8495 - mae: 5.6652 - val_loss: 31.1326 - val_mae: 4.9344\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 38.4777 - mae: 5.4608 - val_loss: 29.1752 - val_mae: 4.7350\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 36.2549 - mae: 5.2625 - val_loss: 27.3315 - val_mae: 4.5382\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 34.1992 - mae: 5.0670 - val_loss: 25.5896 - val_mae: 4.3437\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 32.1755 - mae: 4.8819 - val_loss: 23.9581 - val_mae: 4.1583\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 30.3508 - mae: 4.6981 - val_loss: 22.4136 - val_mae: 3.9886\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28.6415 - mae: 4.5244 - val_loss: 20.9550 - val_mae: 3.8318\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 26.9562 - mae: 4.3543 - val_loss: 19.5915 - val_mae: 3.6810\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 25.4144 - mae: 4.2038 - val_loss: 18.3066 - val_mae: 3.5600\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 23.9099 - mae: 4.0687 - val_loss: 17.0992 - val_mae: 3.4433\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 22.5157 - mae: 3.9360 - val_loss: 15.9585 - val_mae: 3.3255\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 21.1433 - mae: 3.8073 - val_loss: 14.8921 - val_mae: 3.2080\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 19.9616 - mae: 3.6927 - val_loss: 13.8721 - val_mae: 3.0877\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 18.7389 - mae: 3.5703 - val_loss: 12.9157 - val_mae: 2.9779\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17.6176 - mae: 3.4481 - val_loss: 12.0104 - val_mae: 2.8718\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16.5383 - mae: 3.3301 - val_loss: 11.1570 - val_mae: 2.7641\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 15.4512 - mae: 3.2054 - val_loss: 10.3594 - val_mae: 2.6563\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 14.5306 - mae: 3.1056 - val_loss: 9.5958 - val_mae: 2.5545\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 13.5776 - mae: 3.0038 - val_loss: 8.8855 - val_mae: 2.4512\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 12.6820 - mae: 2.9090 - val_loss: 8.2273 - val_mae: 2.3473\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 11.8860 - mae: 2.8211 - val_loss: 7.6141 - val_mae: 2.2420\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 11.0830 - mae: 2.7256 - val_loss: 7.0569 - val_mae: 2.1416\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 10.3828 - mae: 2.6314 - val_loss: 6.5477 - val_mae: 2.0585\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 9.6994 - mae: 2.5431 - val_loss: 6.0892 - val_mae: 1.9817\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 9.1187 - mae: 2.4631 - val_loss: 5.6692 - val_mae: 1.9038\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 8.5506 - mae: 2.3786 - val_loss: 5.2904 - val_mae: 1.8259\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 8.0423 - mae: 2.3026 - val_loss: 4.9435 - val_mae: 1.7476\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 7.5490 - mae: 2.2300 - val_loss: 4.6267 - val_mae: 1.6680\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 7.0970 - mae: 2.1490 - val_loss: 4.3338 - val_mae: 1.5866\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 6.6700 - mae: 2.0773 - val_loss: 4.0671 - val_mae: 1.5252\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 6.2946 - mae: 2.0031 - val_loss: 3.8148 - val_mae: 1.4692\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 5.9114 - mae: 1.9284 - val_loss: 3.5840 - val_mae: 1.4131\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 5.5924 - mae: 1.8608 - val_loss: 3.3753 - val_mae: 1.3658\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 5.2806 - mae: 1.8091 - val_loss: 3.1869 - val_mae: 1.3262\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 4.9941 - mae: 1.7663 - val_loss: 3.0058 - val_mae: 1.2955\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 4.7400 - mae: 1.7258 - val_loss: 2.8303 - val_mae: 1.2682\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 20ms/step - loss: 4.4774 - mae: 1.6793 - val_loss: 2.6619 - val_mae: 1.2357\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 4.2096 - mae: 1.6262 - val_loss: 2.4937 - val_mae: 1.1965\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.9636 - mae: 1.5757 - val_loss: 2.3298 - val_mae: 1.1506\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.7244 - mae: 1.5176 - val_loss: 2.1794 - val_mae: 1.1033\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.5018 - mae: 1.4667 - val_loss: 2.0429 - val_mae: 1.0568\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.2950 - mae: 1.4134 - val_loss: 1.9088 - val_mae: 1.0177\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.1026 - mae: 1.3623 - val_loss: 1.7789 - val_mae: 0.9788\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.9264 - mae: 1.3161 - val_loss: 1.6563 - val_mae: 0.9411\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.7654 - mae: 1.2732 - val_loss: 1.5510 - val_mae: 0.9090\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.6129 - mae: 1.2308 - val_loss: 1.4691 - val_mae: 0.8861\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2.4717 - mae: 1.1885 - val_loss: 1.3999 - val_mae: 0.8657\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2.3482 - mae: 1.1543 - val_loss: 1.3496 - val_mae: 0.8560\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.2271 - mae: 1.1199 - val_loss: 1.3014 - val_mae: 0.8460\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1194 - mae: 1.0916 - val_loss: 1.2564 - val_mae: 0.8378\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 2.0128 - mae: 1.0634 - val_loss: 1.2017 - val_mae: 0.8207\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.9117 - mae: 1.0363 - val_loss: 1.1414 - val_mae: 0.7944\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.8261 - mae: 1.0088 - val_loss: 1.0872 - val_mae: 0.7711\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.7418 - mae: 0.9857 - val_loss: 1.0323 - val_mae: 0.7483\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.6679 - mae: 0.9642 - val_loss: 0.9965 - val_mae: 0.7449\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5925 - mae: 0.9401 - val_loss: 0.9582 - val_mae: 0.7388\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5261 - mae: 0.9194 - val_loss: 0.9284 - val_mae: 0.7360\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.4658 - mae: 0.8993 - val_loss: 0.9042 - val_mae: 0.7346\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4010 - mae: 0.8804 - val_loss: 0.8617 - val_mae: 0.7206\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3440 - mae: 0.8611 - val_loss: 0.8194 - val_mae: 0.7056\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2837 - mae: 0.8415 - val_loss: 0.7746 - val_mae: 0.6882\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2371 - mae: 0.8257 - val_loss: 0.7230 - val_mae: 0.6695\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1845 - mae: 0.8081 - val_loss: 0.6916 - val_mae: 0.6584\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1300 - mae: 0.7871 - val_loss: 0.6722 - val_mae: 0.6519\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0840 - mae: 0.7710 - val_loss: 0.6554 - val_mae: 0.6459\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0371 - mae: 0.7533 - val_loss: 0.6348 - val_mae: 0.6366\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9965 - mae: 0.7377 - val_loss: 0.5970 - val_mae: 0.6175\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9480 - mae: 0.7188 - val_loss: 0.5644 - val_mae: 0.6001\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9050 - mae: 0.7002 - val_loss: 0.5330 - val_mae: 0.5826\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8612 - mae: 0.6831 - val_loss: 0.5011 - val_mae: 0.5646\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8259 - mae: 0.6659 - val_loss: 0.4732 - val_mae: 0.5477\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.7872 - mae: 0.6492 - val_loss: 0.4449 - val_mae: 0.5276\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7514 - mae: 0.6314 - val_loss: 0.4308 - val_mae: 0.5195\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.7173 - mae: 0.6164 - val_loss: 0.4219 - val_mae: 0.5138\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6852 - mae: 0.6032 - val_loss: 0.4079 - val_mae: 0.5034\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6543 - mae: 0.5870 - val_loss: 0.3811 - val_mae: 0.4833\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6230 - mae: 0.5682 - val_loss: 0.3533 - val_mae: 0.4660\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5953 - mae: 0.5512 - val_loss: 0.3252 - val_mae: 0.4465\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5671 - mae: 0.5361 - val_loss: 0.3085 - val_mae: 0.4368\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5429 - mae: 0.5242 - val_loss: 0.3121 - val_mae: 0.4464\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5168 - mae: 0.5124 - val_loss: 0.3029 - val_mae: 0.4419\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4953 - mae: 0.5020 - val_loss: 0.2888 - val_mae: 0.4321\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4717 - mae: 0.4867 - val_loss: 0.2546 - val_mae: 0.4020\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4508 - mae: 0.4723 - val_loss: 0.2378 - val_mae: 0.3876\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4314 - mae: 0.4598 - val_loss: 0.2310 - val_mae: 0.3842\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4125 - mae: 0.4486 - val_loss: 0.2256 - val_mae: 0.3818\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3945 - mae: 0.4379 - val_loss: 0.2171 - val_mae: 0.3753\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3775 - mae: 0.4283 - val_loss: 0.2015 - val_mae: 0.3610\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3616 - mae: 0.4154 - val_loss: 0.1828 - val_mae: 0.3400\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3466 - mae: 0.4044 - val_loss: 0.1742 - val_mae: 0.3314\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3318 - mae: 0.3938 - val_loss: 0.1664 - val_mae: 0.3238\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.3181 - mae: 0.3854 - val_loss: 0.1625 - val_mae: 0.3209\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3056 - mae: 0.3767 - val_loss: 0.1551 - val_mae: 0.3128\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2922 - mae: 0.3650 - val_loss: 0.1418 - val_mae: 0.2944\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2804 - mae: 0.3554 - val_loss: 0.1316 - val_mae: 0.2792\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2701 - mae: 0.3453 - val_loss: 0.1272 - val_mae: 0.2761\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2580 - mae: 0.3366 - val_loss: 0.1227 - val_mae: 0.2712\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2482 - mae: 0.3300 - val_loss: 0.1190 - val_mae: 0.2674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2395 - mae: 0.3224 - val_loss: 0.1110 - val_mae: 0.2547\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2293 - mae: 0.3121 - val_loss: 0.1050 - val_mae: 0.2447\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2219 - mae: 0.3041 - val_loss: 0.1003 - val_mae: 0.2371\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2119 - mae: 0.2960 - val_loss: 0.0977 - val_mae: 0.2353\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2047 - mae: 0.2902 - val_loss: 0.0940 - val_mae: 0.2308\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1995 - mae: 0.2854 - val_loss: 0.0887 - val_mae: 0.2215\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1910 - mae: 0.2744 - val_loss: 0.0824 - val_mae: 0.2042\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1850 - mae: 0.2683 - val_loss: 0.0795 - val_mae: 0.1998\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1778 - mae: 0.2624 - val_loss: 0.0787 - val_mae: 0.2028\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1734 - mae: 0.2600 - val_loss: 0.0754 - val_mae: 0.1940\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1658 - mae: 0.2507 - val_loss: 0.0716 - val_mae: 0.1820\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1609 - mae: 0.2442 - val_loss: 0.0693 - val_mae: 0.1778\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1556 - mae: 0.2390 - val_loss: 0.0674 - val_mae: 0.1768\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1508 - mae: 0.2358 - val_loss: 0.0650 - val_mae: 0.1734\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1464 - mae: 0.2307 - val_loss: 0.0623 - val_mae: 0.1657\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1418 - mae: 0.2249 - val_loss: 0.0609 - val_mae: 0.1630\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1381 - mae: 0.2205 - val_loss: 0.0595 - val_mae: 0.1602\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1341 - mae: 0.2174 - val_loss: 0.0572 - val_mae: 0.1572\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1295 - mae: 0.2123 - val_loss: 0.0556 - val_mae: 0.1546\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1263 - mae: 0.2071 - val_loss: 0.0549 - val_mae: 0.1527\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1227 - mae: 0.2031 - val_loss: 0.0530 - val_mae: 0.1493\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1193 - mae: 0.2005 - val_loss: 0.0516 - val_mae: 0.1472\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1162 - mae: 0.1986 - val_loss: 0.0508 - val_mae: 0.1457\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1133 - mae: 0.1966 - val_loss: 0.0498 - val_mae: 0.1439\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1104 - mae: 0.1923 - val_loss: 0.0487 - val_mae: 0.1416\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1074 - mae: 0.1887 - val_loss: 0.0479 - val_mae: 0.1399\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1050 - mae: 0.1861 - val_loss: 0.0460 - val_mae: 0.1371\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1021 - mae: 0.1852 - val_loss: 0.0453 - val_mae: 0.1354\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0993 - mae: 0.1814 - val_loss: 0.0453 - val_mae: 0.1343\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0972 - mae: 0.1794 - val_loss: 0.0434 - val_mae: 0.1322\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0950 - mae: 0.1784 - val_loss: 0.0428 - val_mae: 0.1313\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0928 - mae: 0.1770 - val_loss: 0.0422 - val_mae: 0.1299\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0907 - mae: 0.1753 - val_loss: 0.0420 - val_mae: 0.1287\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0889 - mae: 0.1730 - val_loss: 0.0420 - val_mae: 0.1283\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0870 - mae: 0.1716 - val_loss: 0.0414 - val_mae: 0.1277\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0853 - mae: 0.1710 - val_loss: 0.0407 - val_mae: 0.1265\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0835 - mae: 0.1683 - val_loss: 0.0413 - val_mae: 0.1279\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0821 - mae: 0.1659 - val_loss: 0.0400 - val_mae: 0.1252\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0801 - mae: 0.1659 - val_loss: 0.0390 - val_mae: 0.1229\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0792 - mae: 0.1669 - val_loss: 0.0389 - val_mae: 0.1226\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0769 - mae: 0.1621 - val_loss: 0.0399 - val_mae: 0.1247\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0757 - mae: 0.1604 - val_loss: 0.0392 - val_mae: 0.1233\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0738 - mae: 0.1593 - val_loss: 0.0376 - val_mae: 0.1195\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0730 - mae: 0.1614 - val_loss: 0.0370 - val_mae: 0.1177\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0713 - mae: 0.1578 - val_loss: 0.0393 - val_mae: 0.1249\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0707 - mae: 0.1559 - val_loss: 0.0396 - val_mae: 0.1271\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0686 - mae: 0.1543 - val_loss: 0.0351 - val_mae: 0.1126\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0680 - mae: 0.1582 - val_loss: 0.0353 - val_mae: 0.1124\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0665 - mae: 0.1546 - val_loss: 0.0379 - val_mae: 0.1189\n",
      "Epoch 173/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0666 - mae: 0.1541 - val_loss: 0.0399 - val_mae: 0.1294\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0642 - mae: 0.1480 - val_loss: 0.0354 - val_mae: 0.1110\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0636 - mae: 0.1538 - val_loss: 0.0340 - val_mae: 0.1080\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0624 - mae: 0.1526 - val_loss: 0.0351 - val_mae: 0.1132\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0610 - mae: 0.1478 - val_loss: 0.0361 - val_mae: 0.1203\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0605 - mae: 0.1473 - val_loss: 0.0342 - val_mae: 0.1107\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0589 - mae: 0.1462 - val_loss: 0.0335 - val_mae: 0.1074\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0581 - mae: 0.1460 - val_loss: 0.0341 - val_mae: 0.1082\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0573 - mae: 0.1448 - val_loss: 0.0356 - val_mae: 0.1125\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0565 - mae: 0.1423 - val_loss: 0.0351 - val_mae: 0.1089\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0563 - mae: 0.1427 - val_loss: 0.0360 - val_mae: 0.1131\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0547 - mae: 0.1400 - val_loss: 0.0333 - val_mae: 0.1049\n",
      "Epoch 185/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0541 - mae: 0.1416 - val_loss: 0.0329 - val_mae: 0.1058\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0531 - mae: 0.1405 - val_loss: 0.0330 - val_mae: 0.1101\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0529 - mae: 0.1403 - val_loss: 0.0334 - val_mae: 0.1135\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0523 - mae: 0.1412 - val_loss: 0.0317 - val_mae: 0.1046\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0509 - mae: 0.1383 - val_loss: 0.0321 - val_mae: 0.1060\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0504 - mae: 0.1370 - val_loss: 0.0334 - val_mae: 0.1076\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0497 - mae: 0.1346 - val_loss: 0.0325 - val_mae: 0.1028\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0492 - mae: 0.1353 - val_loss: 0.0325 - val_mae: 0.1032\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0485 - mae: 0.1313 - val_loss: 0.0343 - val_mae: 0.1124\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0483 - mae: 0.1324 - val_loss: 0.0311 - val_mae: 0.1019\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0471 - mae: 0.1324 - val_loss: 0.0301 - val_mae: 0.1001\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0468 - mae: 0.1326 - val_loss: 0.0310 - val_mae: 0.1026\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0460 - mae: 0.1303 - val_loss: 0.0305 - val_mae: 0.1006\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0454 - mae: 0.1303 - val_loss: 0.0305 - val_mae: 0.0993\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0450 - mae: 0.1296 - val_loss: 0.0324 - val_mae: 0.1024\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0444 - mae: 0.1265 - val_loss: 0.0331 - val_mae: 0.1062\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0438 - mae: 0.1259 - val_loss: 0.0316 - val_mae: 0.1016\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0431 - mae: 0.1267 - val_loss: 0.0300 - val_mae: 0.0973\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0430 - mae: 0.1281 - val_loss: 0.0302 - val_mae: 0.0986\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0421 - mae: 0.1250 - val_loss: 0.0314 - val_mae: 0.1039\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0425 - mae: 0.1252 - val_loss: 0.0313 - val_mae: 0.1030\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0413 - mae: 0.1229 - val_loss: 0.0296 - val_mae: 0.0966\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0409 - mae: 0.1237 - val_loss: 0.0295 - val_mae: 0.0971\n",
      "Epoch 208/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0402 - mae: 0.1224 - val_loss: 0.0293 - val_mae: 0.0976\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0396 - mae: 0.1219 - val_loss: 0.0292 - val_mae: 0.0984\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0393 - mae: 0.1216 - val_loss: 0.0294 - val_mae: 0.0990\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0390 - mae: 0.1199 - val_loss: 0.0300 - val_mae: 0.1008\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0385 - mae: 0.1190 - val_loss: 0.0294 - val_mae: 0.0965\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0380 - mae: 0.1181 - val_loss: 0.0300 - val_mae: 0.0967\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0374 - mae: 0.1164 - val_loss: 0.0302 - val_mae: 0.0984\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0369 - mae: 0.1156 - val_loss: 0.0295 - val_mae: 0.0985\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0367 - mae: 0.1164 - val_loss: 0.0284 - val_mae: 0.0969\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0363 - mae: 0.1163 - val_loss: 0.0278 - val_mae: 0.0947\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0359 - mae: 0.1163 - val_loss: 0.0280 - val_mae: 0.0953\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0354 - mae: 0.1147 - val_loss: 0.0284 - val_mae: 0.0971\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0352 - mae: 0.1136 - val_loss: 0.0294 - val_mae: 0.0987\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0347 - mae: 0.1126 - val_loss: 0.0279 - val_mae: 0.0951\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0343 - mae: 0.1137 - val_loss: 0.0273 - val_mae: 0.0937\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0340 - mae: 0.1131 - val_loss: 0.0284 - val_mae: 0.0966\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0336 - mae: 0.1112 - val_loss: 0.0289 - val_mae: 0.0971\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0333 - mae: 0.1101 - val_loss: 0.0282 - val_mae: 0.0949\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0337 - mae: 0.1136 - val_loss: 0.0276 - val_mae: 0.0931\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0327 - mae: 0.1108 - val_loss: 0.0280 - val_mae: 0.0948\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0323 - mae: 0.1077 - val_loss: 0.0289 - val_mae: 0.0966\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0320 - mae: 0.1069 - val_loss: 0.0280 - val_mae: 0.0940\n",
      "Epoch 230/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0316 - mae: 0.1070 - val_loss: 0.0277 - val_mae: 0.0936\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0315 - mae: 0.1082 - val_loss: 0.0274 - val_mae: 0.0940\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0310 - mae: 0.1073 - val_loss: 0.0275 - val_mae: 0.0947\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=10)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          validation_split = 0.2,\n",
    "          callbacks=[es],\n",
    "          epochs=1000, \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8591792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 20)                460       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                210       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c616331d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0256 - mae: 0.1248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.025575213134288788, 0.1247534304857254]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1747227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28d762c20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb5d81ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28d8aa350>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"mae\"], label = \"Train MAE\")\n",
    "plt.plot(history.history[\"val_mae\"], label = \"Validation MAE\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c6191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51b969df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 33, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbe3bb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 5.91,  0.94],\n",
       "        [ 5.83,  1.15],\n",
       "        [ 5.59,  1.24],\n",
       "        ...,\n",
       "        [ 2.33,  6.1 ],\n",
       "        [ 2.3 ,  6.3 ],\n",
       "        [ 2.27,  6.4 ]],\n",
       "\n",
       "       [[ 2.44,  8.91],\n",
       "        [ 2.59,  9.29],\n",
       "        [ 2.1 ,  9.76],\n",
       "        ...,\n",
       "        [ 1.54, 13.4 ],\n",
       "        [ 1.54, 13.4 ],\n",
       "        [ 1.54, 13.4 ]],\n",
       "\n",
       "       [[ 6.25,  0.32],\n",
       "        [ 7.04,  0.4 ],\n",
       "        [ 7.36,  0.65],\n",
       "        ...,\n",
       "        [ 4.08,  6.6 ],\n",
       "        [ 3.97,  6.6 ],\n",
       "        [ 3.86,  6.7 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 6.49,  2.32],\n",
       "        [ 5.77,  2.91],\n",
       "        [ 4.91,  3.31],\n",
       "        ...,\n",
       "        [ 1.69,  9.7 ],\n",
       "        [ 1.68,  9.7 ],\n",
       "        [ 1.66, 10.  ]],\n",
       "\n",
       "       [[ 2.23,  6.86],\n",
       "        [ 2.25,  6.07],\n",
       "        [ 2.4 ,  6.04],\n",
       "        ...,\n",
       "        [ 1.3 , 10.5 ],\n",
       "        [ 1.33, 10.6 ],\n",
       "        [ 1.38, 10.8 ]],\n",
       "\n",
       "       [[ 4.03,  9.57],\n",
       "        [ 3.54,  9.88],\n",
       "        [ 3.16, 10.69],\n",
       "        ...,\n",
       "        [ 1.92, 12.2 ],\n",
       "        [ 1.99, 12.4 ],\n",
       "        [ 1.87, 12.5 ]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "150a0828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 352ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.554513]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[[2.37,7.53]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e4afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d37cca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f40bb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33855735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8bf54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065014b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a674e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5165c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e79176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012d5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79b0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40733f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd3f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c6e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1fd5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd22a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284dd091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995677aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8221fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f1e1935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>fertility</th>\n",
       "      <th>avg_years_of_schooling</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2.37</td>\n",
       "      <td>7.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>6.15</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>4.56</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>6.35</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country  fertility  avg_years_of_schooling\n",
       "Year                                               \n",
       "1960     Germany       2.37                    7.53\n",
       "1960    Thailand       6.15                    2.07\n",
       "1960  Kazakhstan       4.56                    3.07\n",
       "1960     Vietnam       6.35                    2.01\n",
       "1960       Kenya       7.95                    1.21"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a51dec0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>fertility</th>\n",
       "      <th>avg_years_of_schooling</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2.37</td>\n",
       "      <td>7.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2.50</td>\n",
       "      <td>7.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2.03</td>\n",
       "      <td>7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.45</td>\n",
       "      <td>7.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.44</td>\n",
       "      <td>7.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.37</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.45</td>\n",
       "      <td>8.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.33</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.29</td>\n",
       "      <td>9.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.28</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.24</td>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.25</td>\n",
       "      <td>9.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.30</td>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.36</td>\n",
       "      <td>10.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.36</td>\n",
       "      <td>10.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.38</td>\n",
       "      <td>11.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.35</td>\n",
       "      <td>11.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.34</td>\n",
       "      <td>12.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.34</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.36</td>\n",
       "      <td>12.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.34</td>\n",
       "      <td>13.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.33</td>\n",
       "      <td>13.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.37</td>\n",
       "      <td>13.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.38</td>\n",
       "      <td>13.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.36</td>\n",
       "      <td>13.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.39</td>\n",
       "      <td>13.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.39</td>\n",
       "      <td>13.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.41</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.42</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.47</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.50</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.60</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1.57</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Country  fertility  avg_years_of_schooling\n",
       "Year                                            \n",
       "1960  Germany       2.37                    7.53\n",
       "1965  Germany       2.50                    7.68\n",
       "1970  Germany       2.03                    7.71\n",
       "1975  Germany       1.45                    7.58\n",
       "1980  Germany       1.44                    7.63\n",
       "1985  Germany       1.37                    7.55\n",
       "1990  Germany       1.45                    8.77\n",
       "1991  Germany       1.33                    8.90\n",
       "1992  Germany       1.29                    9.10\n",
       "1993  Germany       1.28                    9.30\n",
       "1994  Germany       1.24                    9.50\n",
       "1995  Germany       1.25                    9.70\n",
       "1996  Germany       1.30                    9.80\n",
       "1997  Germany       1.35                   10.00\n",
       "1998  Germany       1.36                   10.20\n",
       "1999  Germany       1.36                   10.30\n",
       "2000  Germany       1.38                   11.20\n",
       "2001  Germany       1.35                   11.70\n",
       "2002  Germany       1.34                   12.10\n",
       "2003  Germany       1.34                   12.50\n",
       "2004  Germany       1.36                   12.90\n",
       "2005  Germany       1.34                   13.30\n",
       "2006  Germany       1.33                   13.60\n",
       "2007  Germany       1.37                   13.70\n",
       "2008  Germany       1.38                   13.70\n",
       "2009  Germany       1.36                   13.80\n",
       "2010  Germany       1.39                   13.80\n",
       "2011  Germany       1.39                   13.90\n",
       "2012  Germany       1.41                   14.00\n",
       "2013  Germany       1.42                   14.00\n",
       "2014  Germany       1.47                   14.00\n",
       "2015  Germany       1.50                   14.10\n",
       "2016  Germany       1.60                   14.10\n",
       "2017  Germany       1.57                   14.10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Country']=='Germany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16dbc4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.082653]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[[1.57, 14.10]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e5fce",
   "metadata": {},
   "source": [
    "# Rascunho !!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27edd881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ea8975c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 33, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a01eb9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "um_pais = np.array(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaa5a14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "um_pais.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0409902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 33, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "um_pais = np.expand_dims(um_pais.astype(np.float32), axis=0)\n",
    "um_pais.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4cfbe61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 33, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "um_pais.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6fffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99cb19fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dacf7a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.1]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pais = np.array(y_train[0])\n",
    "y_pais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16ac2b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pais.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "558f936c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pais = np.expand_dims(y_pais.astype(np.float32), axis=-1)\n",
    "y_pais.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c427625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 208.7292 - mae: 14.4475WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 1s 741ms/step - loss: 208.7292 - mae: 14.4475\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 206.8787 - mae: 14.3833WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 206.8787 - mae: 14.3833\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 205.0333 - mae: 14.3190WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 205.0333 - mae: 14.3190\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 203.1935 - mae: 14.2546WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 203.1935 - mae: 14.2546\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 201.3596 - mae: 14.1901WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 201.3596 - mae: 14.1901\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 199.5321 - mae: 14.1256WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 199.5321 - mae: 14.1256\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 198.0161 - mae: 14.0718WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 198.0161 - mae: 14.0718\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 196.7052 - mae: 14.0252WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 196.7052 - mae: 14.0252\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 195.5601 - mae: 13.9843WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 195.5601 - mae: 13.9843\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 194.5460 - mae: 13.9480WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 194.5460 - mae: 13.9480\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 193.5293 - mae: 13.9115WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 193.5293 - mae: 13.9115\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 192.5122 - mae: 13.8749WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 192.5122 - mae: 13.8749\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 191.4963 - mae: 13.8382WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 191.4963 - mae: 13.8382\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 190.4829 - mae: 13.8016WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 190.4829 - mae: 13.8016\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 189.4727 - mae: 13.7649WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 189.4727 - mae: 13.7649\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 188.4666 - mae: 13.7283WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 188.4666 - mae: 13.7283\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 187.4652 - mae: 13.6918WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 187.4652 - mae: 13.6918\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 186.4688 - mae: 13.6554WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 186.4688 - mae: 13.6554\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 185.4777 - mae: 13.6190WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 185.4777 - mae: 13.6190\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 184.4921 - mae: 13.5828WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 184.4921 - mae: 13.5828\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 183.5119 - mae: 13.5467WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 183.5119 - mae: 13.5467\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 182.5371 - mae: 13.5106WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 182.5371 - mae: 13.5106\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 181.5675 - mae: 13.4747WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 181.5675 - mae: 13.4747\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 180.6027 - mae: 13.4389WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 180.6027 - mae: 13.4389\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 179.6422 - mae: 13.4031WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 179.6422 - mae: 13.4031\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 178.6856 - mae: 13.3673WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 178.6856 - mae: 13.3673\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 177.7321 - mae: 13.3316WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 177.7321 - mae: 13.3316\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 176.7812 - mae: 13.2959WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 176.7812 - mae: 13.2959\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 175.8323 - mae: 13.2602WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 175.8323 - mae: 13.2602\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 174.8848 - mae: 13.2244WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 174.8848 - mae: 13.2244\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 173.9382 - mae: 13.1886WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 173.9382 - mae: 13.1886\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 172.9921 - mae: 13.1526WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 172.9921 - mae: 13.1526\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 172.0462 - mae: 13.1166WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 172.0462 - mae: 13.1166\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 171.1070 - mae: 13.0808WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 171.1070 - mae: 13.0808\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 170.1898 - mae: 13.0457WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 170.1898 - mae: 13.0457\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 169.2694 - mae: 13.0104WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 169.2694 - mae: 13.0104\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 168.3461 - mae: 12.9748WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 168.3461 - mae: 12.9748\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 167.4201 - mae: 12.9391WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 167.4201 - mae: 12.9391\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 166.4916 - mae: 12.9032WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 166.4916 - mae: 12.9032\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 165.5608 - mae: 12.8670WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 165.5608 - mae: 12.8670\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 164.6277 - mae: 12.8307WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 164.6277 - mae: 12.8307\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 163.6925 - mae: 12.7942WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 163.6925 - mae: 12.7942\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 162.7551 - mae: 12.7576WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 162.7551 - mae: 12.7576\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 161.8155 - mae: 12.7207WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 161.8155 - mae: 12.7207\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 160.8736 - mae: 12.6836WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 160.8736 - mae: 12.6836\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 159.9294 - mae: 12.6463WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 159.9294 - mae: 12.6463\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 158.9824 - mae: 12.6088WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 158.9824 - mae: 12.6088\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 158.0327 - mae: 12.5711WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 158.0327 - mae: 12.5711\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 157.0797 - mae: 12.5331WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 157.0797 - mae: 12.5331\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 156.1231 - mae: 12.4949WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 156.1231 - mae: 12.4949\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 155.1626 - mae: 12.4564WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 155.1626 - mae: 12.4564\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 154.2070 - mae: 12.4180WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 154.2070 - mae: 12.4180\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 153.2453 - mae: 12.3792WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 153.2453 - mae: 12.3792\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 152.2744 - mae: 12.3400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 152.2744 - mae: 12.3400\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 151.2943 - mae: 12.3002WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 151.2943 - mae: 12.3002\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 150.3049 - mae: 12.2599WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 150.3049 - mae: 12.2599\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 149.3079 - mae: 12.2192WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 149.3079 - mae: 12.2192\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 148.3112 - mae: 12.1783WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 148.3112 - mae: 12.1783\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 147.3076 - mae: 12.1370WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 147.3076 - mae: 12.1370\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 146.2951 - mae: 12.0953WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 146.2951 - mae: 12.0953\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 145.2727 - mae: 12.0529WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 145.2727 - mae: 12.0529\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 144.2430 - mae: 12.0101WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 144.2430 - mae: 12.0101\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 143.2057 - mae: 11.9669WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 143.2057 - mae: 11.9669\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 142.1606 - mae: 11.9231WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 142.1606 - mae: 11.9231\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 141.1097 - mae: 11.8790WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 141.1097 - mae: 11.8790\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 140.1459 - mae: 11.8383WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 140.1459 - mae: 11.8383\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 139.2103 - mae: 11.7987WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 139.2103 - mae: 11.7987\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 138.1934 - mae: 11.7556WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 138.1934 - mae: 11.7556\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 137.1106 - mae: 11.7094WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 137.1106 - mae: 11.7094\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 135.9860 - mae: 11.6613WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 135.9860 - mae: 11.6613\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 134.9635 - mae: 11.6174WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 134.9635 - mae: 11.6174\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 133.9213 - mae: 11.5724WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 133.9213 - mae: 11.5724\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 132.8609 - mae: 11.5265WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 132.8609 - mae: 11.5265\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 131.7808 - mae: 11.4796WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 131.7808 - mae: 11.4796\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 130.6842 - mae: 11.4317WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 130.6842 - mae: 11.4317\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 129.5711 - mae: 11.3829WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 129.5711 - mae: 11.3829\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 128.4929 - mae: 11.3355WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 128.4929 - mae: 11.3355\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 127.3928 - mae: 11.2868WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 127.3928 - mae: 11.2868\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 126.2565 - mae: 11.2364WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 126.2565 - mae: 11.2364\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 125.3130 - mae: 11.1943WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 125.3130 - mae: 11.1943\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 124.3840 - mae: 11.1528WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 124.3840 - mae: 11.1528\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 123.4323 - mae: 11.1100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 123.4323 - mae: 11.1100\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 122.4613 - mae: 11.0662WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step - loss: 122.4613 - mae: 11.0662\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 121.4746 - mae: 11.0216WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 121.4746 - mae: 11.0216\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 120.4754 - mae: 10.9761WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 120.4754 - mae: 10.9761\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 119.5295 - mae: 10.9330WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 119.5295 - mae: 10.9330\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 118.5394 - mae: 10.8876WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 118.5394 - mae: 10.8876\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 117.5117 - mae: 10.8403WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 117.5117 - mae: 10.8403\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 116.5011 - mae: 10.7936WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 116.5011 - mae: 10.7936\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 115.5178 - mae: 10.7479WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 115.5178 - mae: 10.7479\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 114.5321 - mae: 10.7020WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 114.5321 - mae: 10.7020\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 113.5459 - mae: 10.6558WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 113.5459 - mae: 10.6558\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 112.5614 - mae: 10.6095WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 112.5614 - mae: 10.6095\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 111.5802 - mae: 10.5632WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 111.5802 - mae: 10.5632\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 110.6300 - mae: 10.5181WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 110.6300 - mae: 10.5181\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 109.6588 - mae: 10.4718WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 109.6588 - mae: 10.4718\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 108.6857 - mae: 10.4252WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 108.6857 - mae: 10.4252\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 107.7335 - mae: 10.3795WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 107.7335 - mae: 10.3795\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 106.8084 - mae: 10.3348WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 106.8084 - mae: 10.3348\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 105.8768 - mae: 10.2896WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 105.8768 - mae: 10.2896\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=20, activation='tanh'))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "model.compile(loss='mse', \n",
    "              optimizer='adam', #change to adam\n",
    "                metrics=['mae'])\n",
    "\n",
    "es = EarlyStopping(patience=10)\n",
    "\n",
    "history = model.fit(um_pais, y_pais,\n",
    "          #validation_split = 0.2,\n",
    "          callbacks=[es],\n",
    "          epochs=100, \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1966eda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 191ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.0492275]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[[1.39, 13.80]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d373aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa13c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d921f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960e52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436fdfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dff6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
